{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metadata_dict import dcp_to_tier1_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \".\"\n",
    "file_name = \"ImmuneLandscapeccRCC_metadata_30-01-2023.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcp_spreadsheet = pd.read_excel(path + \"/dcp_spreadsheets/\" + file_name, sheet_name=None, skiprows= [0,1,2,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uns tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_info = dcp_spreadsheet['Project']\n",
    "contributors = pd.read_excel(path + \"/dcp_spreadsheets/\" + file_name, sheet_name='Project - Contributors', skiprows= [0,1,2,4])\n",
    "\n",
    "\n",
    "uns = {\n",
    "    \"title\": project_info.iloc[0]['project.project_core.project_title'], \n",
    "    \"study_pi\": contributors['project.contributors.name']\\\n",
    "                    [max(\\\n",
    "                        contributors[contributors['project.contributors.corresponding_contributor'] == True]\\\n",
    "                            .index)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "uns = pd.DataFrame(uns, index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obs tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_biomaterial = pd.read_csv(path + \"/flat_dcp/\"  + file_name.replace(\".xlsx\", \"_flat_biomaterial.csv\"))\n",
    "flat_biomaterial = pd.read_csv(path + \"/flat_dcp/\"  + file_name.replace(\".xlsx\", \"_denormalised_biomaterial.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_tier1 = flat_biomaterial.rename(columns=dcp_to_tier1_mapping)\\\n",
    "    .drop(columns=[col for col in flat_biomaterial if col not in dcp_to_tier1_mapping.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sample_source' in flat_tier1.keys():\n",
    "    # flat_tier1.loc[(flat_tier1['sample_source'] == 'yes') & \\\n",
    "    #     (flat_tier1['sample_collection_method'].isin(['brush', 'scraping', 'biopsy', 'blood draw', 'body fluid', 'other'])),\\\n",
    "    #         'sample_source'] = 'surgical donor'\n",
    "    # Normally we would use the specimen_from_organism.transplant_organ field but since it is not populated yet, we use the sample_collection_method\n",
    "    # In this case however, we have nephrectomy for all donors which is a surgical recession but is also a surgical donation. Therefore, we manually change that here\n",
    "    flat_tier1['sample_source'] = 'surgical donor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sex_ontology_term_id' in flat_tier1.keys():\n",
    "    sex_ontology = {\n",
    "        'sex_ontology_term_id':\n",
    "            {\n",
    "                'female': 'PATO:0000383',\n",
    "                'male': 'PATO:0000384'\n",
    "            }           \n",
    "    }\n",
    "    flat_tier1.replace(sex_ontology, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def library_to_tissue_type(library_id, dcp_spreadsheet):\n",
    "    tissue_type_dict = {\n",
    "        'specimen_from_organism.biomaterial_core.biomaterial_id': 'tissue',\n",
    "        'cell_line.biomaterial_core.biomaterial_id': 'cell culture',\n",
    "        'organoid.biomaterial_core.biomaterial_id': 'organoid'\n",
    "    }\n",
    "    row = dcp_spreadsheet['Cell suspension'][dcp_spreadsheet['Cell suspension']['cell_suspension.biomaterial_core.biomaterial_id'] == library_id]\n",
    "    tissue_type = [tissue_type for dcp_type, tissue_type in tissue_type_dict.items() if dcp_type in row.columns and not any(row[dcp_type].isna())]\n",
    "    if len(tissue_type) > 1:\n",
    "        raise ValueError(f'Multiple input biomaterials for {library_id}')\n",
    "    return tissue_type[0]\n",
    "\n",
    "flat_tier1['tissue_type'] = flat_tier1['library_id'].apply(lambda x: library_to_tissue_type(x, dcp_spreadsheet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cg/kjj0b2v92rx2c4s4d0wc5by80000gp/T/ipykernel_95035/681698269.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'healthy' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  flat_tier1.loc[(['sampled_site_condition_donor'] == 'normal') & (flat_tier1['sampled_site_condition_specimen'] == 'normal'), 'sampled_site_condition'] = 'healthy'\n"
     ]
    }
   ],
   "source": [
    "flat_tier1['sampled_site_condition'] = np.nan\n",
    "flat_tier1.loc[(['sampled_site_condition_donor'] == 'normal') & (flat_tier1['sampled_site_condition_specimen'] == 'normal'), 'sampled_site_condition'] = 'healthy'\n",
    "flat_tier1.loc[(['sampled_site_condition_donor'] != 'normal') & (flat_tier1['sampled_site_condition_specimen'] == 'normal'), 'sampled_site_condition'] = 'adjacent'\n",
    "flat_tier1.loc[(['sampled_site_condition_donor'] != 'normal') & (flat_tier1['sampled_site_condition_specimen'] != 'normal'), 'sampled_site_condition'] = 'diseased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_to_dev(age):\n",
    "    # TODO add more options\n",
    "    # Unknown = unknown\n",
    "    # Embryonic stage = A term from the set of Carnegie stages 1-23 = (up to 8 weeks after conception; e.g. HsapDv:0000003)\n",
    "    # Fetal development = A term from the set of 9 to 38 week post-fertilization human stages = (9 weeks after conception and before birth; e.g. HsapDv:0000046)\n",
    "    # Post natal =\n",
    "    age_to_dev_dict = {\n",
    "        (0, 14): 'HsapDv:0000264',\n",
    "        (15, 19): 'HsapDv:0000268',\n",
    "        (20, 29): 'HsapDv:0000237',\n",
    "        (30, 39): 'HsapDv:0000238',\n",
    "        (40, 49): 'HsapDv:0000239',\n",
    "        (50, 59): 'HsapDv:0000240',\n",
    "        (60, 69): 'HsapDv:0000241',\n",
    "        (70, 79): 'HsapDv:0000242',\n",
    "        (80, 89): 'HsapDv:0000243'\n",
    "    }\n",
    "    for age_range, label in age_to_dev_dict.items():\n",
    "        if age_range[0] <= age <= age_range[1]:\n",
    "            return label\n",
    "\n",
    "if (flat_tier1['organism_ontology_term_id'] == 9606).all():\n",
    "    flat_tier1['development_stage_ontology_term_id'] = flat_tier1['development_stage_ontology_term_id'].apply(age_to_dev)\n",
    "else:\n",
    "    print(\"Please convert the age to developomental stage ontology\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this dataset the preservation and storage method has not been submitted, but it is mentioned in the article that the samples were snap frozen with liquid nitrogen & stored at -80C\n",
    "flat_tier1['sample_preservation_method'] = 'frozen in liquid nitrogen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspension_type_dict = {\n",
    "    'suspension_type':\n",
    "    {\n",
    "        'single cell': 'cell',\n",
    "        'single nucleus': 'nucleus'\n",
    "    }\n",
    "}\n",
    "flat_tier1.replace(suspension_type_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_enrichment_dict = {\n",
    "    'cell_enrichment':\n",
    "    {\n",
    "        'DAPI-': 'na',\n",
    "        np.nan: 'na'\n",
    "    }\n",
    "}\n",
    "flat_tier1.replace(cell_enrichment_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_tier1['is_primary_data'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_tier1['alignment_software'] = flat_tier1['alignment_software'] & flat_tier1['alignment_software_version']\n",
    "flat_tier1['alignment_software'] = 'Cellranger v3.0.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From pooled diseases, we will use MONDO:0005005, instead of HP:0002716\n"
     ]
    }
   ],
   "source": [
    "unique_diseases = flat_tier1['disease_ontology_term_id'].str.split(\"\\\\|\\\\|\", expand=True, n=1).drop_duplicates().dropna()\n",
    "if unique_diseases.shape[1] > 1:\n",
    "    selected_disease = \", \".join(np.unique(unique_diseases[0]))\n",
    "    unselected_diseases = \" and \".join(unique_diseases[1])\n",
    "    print(f\"From pooled diseases, we will use {selected_disease}, instead of {unselected_diseases}\")\n",
    "\n",
    "    flat_tier1['disease_ontology_term_id'] = flat_tier1['disease_ontology_term_id'].str.split(\"\\\\|\\\\|\").str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune obs dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_tier1.drop(columns=['sampled_site_condition_donor', 'sampled_site_condition_specimen'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template is at sample level, therefore the library level fields will be collapsed with comma\n",
    "def collapse_values(series):\n",
    "    return \", \".join(series.astype(str))\n",
    "\n",
    "flat_tier1_sample = flat_tier1.groupby('sample_id').agg(collapse_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to xlsx and `csv`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tier1_output = \"tier1_output/\" + file_name.replace(\".xlsx\", \"_Tier1.xlsx\")\n",
    "! cp 'HCA_Tier 1_ Technical Metadata template_v0.1.xlsx' $tier1_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tier1_spreadsheet = {}\n",
    "tier1_spreadsheet['Tier 1_uns'] = uns\n",
    "tier1_spreadsheet['Tier 1_obs'] = flat_tier1_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_dict = pd.read_excel(tier1_output, header=1, sheet_name=None)\n",
    "for sheet_name, excel_df in excel_dict.items():\n",
    "    if sheet_name in tier1_spreadsheet:\n",
    "        py_df = tier1_spreadsheet[sheet_name]\n",
    "        excel_dict[sheet_name] = pd.concat([excel_df, py_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(tier1_output) as writer:\n",
    "    for tab in excel_dict:\n",
    "        excel_dict[tab].to_excel(writer, sheet_name=tab, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tier1_spreadsheet['Tier 1_uns'].to_csv(\"tier1_output/\" + file_name.replace('.xlsx', '_tier1_uns.csv'))\n",
    "tier1_spreadsheet['Tier 1_obs'].to_csv(\"tier1_output/\" + file_name.replace('.xlsx', '_tier1_obs.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
